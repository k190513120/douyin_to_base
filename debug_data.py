#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•è„šæœ¬ï¼šåˆ†ææŠ–éŸ³æ•°æ®å‡†ç¡®æ€§é—®é¢˜
"""

import json
import sys
from douyin_scraper import DouyinScraper
from feishu_writer import FeishuWriter, BaseConfig, DouyinDataTypeMapper
import os
from dotenv import load_dotenv, find_dotenv

def print_json_pretty(data, title="æ•°æ®"):
    """ç¾åŒ–æ‰“å°JSONæ•°æ®"""
    print(f"\n{'='*50}")
    print(f"{title}")
    print(f"{'='*50}")
    print(json.dumps(data, indent=2, ensure_ascii=False))
    print(f"{'='*50}\n")

def analyze_single_video(url, max_videos=1):
    """åˆ†æå•ä¸ªè§†é¢‘çš„æ•°æ®å‡†ç¡®æ€§"""
    
    # 1. æŠ“å–åŸå§‹æ•°æ®
    print("ğŸ” å¼€å§‹æŠ“å–æŠ–éŸ³æ•°æ®...")
    scraper = DouyinScraper()
    videos_data = scraper.fetch_all_videos(url, max_videos=max_videos)
    
    if not videos_data:
        print("âŒ æ²¡æœ‰æŠ“å–åˆ°ä»»ä½•æ•°æ®")
        return
    
    print(f"âœ… æˆåŠŸæŠ“å–åˆ° {len(videos_data)} æ¡æ•°æ®")
    
    # 2. åˆ†æç¬¬ä¸€æ¡æ•°æ®
    video_data = videos_data[0]
    print_json_pretty(video_data, "åŸå§‹æŠ–éŸ³æ•°æ®ç»“æ„")
    
    # 3. åˆ†ææ•°æ®å­—æ®µ
    print("\nğŸ“Š æ•°æ®å­—æ®µåˆ†æ:")
    print("-" * 50)
    
    def analyze_nested_dict(data, prefix="", level=0):
        """é€’å½’åˆ†æåµŒå¥—å­—å…¸ç»“æ„"""
        indent = "  " * level
        for key, value in data.items():
            full_key = f"{prefix}.{key}" if prefix else key
            if isinstance(value, dict):
                print(f"{indent}{key}: (dict, {len(value)} keys)")
                if level < 2:  # é™åˆ¶é€’å½’æ·±åº¦
                    analyze_nested_dict(value, full_key, level + 1)
            elif isinstance(value, list):
                print(f"{indent}{key}: (list, {len(value)} items)")
                if value and isinstance(value[0], dict) and level < 2:
                    print(f"{indent}  â””â”€ ç¬¬ä¸€ä¸ªå…ƒç´ :")
                    analyze_nested_dict(value[0], f"{full_key}[0]", level + 2)
            else:
                value_str = str(value)[:50] + "..." if len(str(value)) > 50 else str(value)
                print(f"{indent}{key}: {type(value).__name__} = {value_str}")
    
    analyze_nested_dict(video_data)
    
    # 4. æ¨¡æ‹Ÿé£ä¹¦å†™å…¥å™¨çš„æ•°æ®å¤„ç†
    print("\nğŸ”„ æ¨¡æ‹Ÿæ•°æ®å¤„ç†è¿‡ç¨‹:")
    print("-" * 50)
    
    # åŠ è½½é…ç½®
    load_dotenv(find_dotenv())
    config = BaseConfig(
        app_token=os.environ.get('APP_TOKEN'),
        personal_base_token=os.environ.get('PERSONAL_BASE_TOKEN'),
        table_id=os.environ.get('TABLE_ID'),
        region='domestic'
    )
    
    writer = FeishuWriter(config)
    processed_fields = writer._prepare_record_fields(video_data)
    
    print_json_pretty(processed_fields, "å¤„ç†åçš„å­—æ®µæ•°æ®")
    
    # 5. å¯¹æ¯”åˆ†æ
    print("\nğŸ” æ•°æ®å‡†ç¡®æ€§å¯¹æ¯”åˆ†æ:")
    print("-" * 50)
    
    # æ£€æŸ¥å…³é”®å­—æ®µçš„æ˜ å°„ï¼ˆä½¿ç”¨ä¸feishu_writerç›¸åŒçš„é€»è¾‘ï¼‰
    key_mappings = {
        'aweme_id': video_data.get('aweme_id'),
        'desc': video_data.get('title', '') or video_data.get('desc', ''),
        'create_time': video_data.get('create_time'),
        'author_nickname': video_data.get('author_name', '') or video_data.get('author', {}).get('nickname', ''),
        'author_unique_id': video_data.get('author', {}).get('unique_id'),
        'author_uid': video_data.get('author_uid', '') or video_data.get('author', {}).get('uid', ''),
        'digg_count': video_data.get('digg_count', 0) or video_data.get('statistics', {}).get('digg_count', 0),
        'comment_count': video_data.get('comment_count', 0) or video_data.get('statistics', {}).get('comment_count', 0),
        'share_count': video_data.get('share_count', 0) or video_data.get('statistics', {}).get('share_count', 0),
        'play_count': video_data.get('play_count', 0) or video_data.get('statistics', {}).get('play_count', 0),
        'collect_count': video_data.get('collect_count', 0) or video_data.get('statistics', {}).get('collect_count', 0),
    }
    
    print("å­—æ®µæ˜ å°„å¯¹æ¯”:")
    for field_name, original_value in key_mappings.items():
        processed_value = processed_fields.get(field_name)
        converted_value = DouyinDataTypeMapper.convert_value(field_name, original_value)
        
        print(f"\n{field_name}:")
        print(f"  åŸå§‹å€¼: {original_value} ({type(original_value).__name__})")
        print(f"  å¤„ç†å€¼: {processed_value} ({type(processed_value).__name__})")
        print(f"  è½¬æ¢å€¼: {converted_value} ({type(converted_value).__name__})")
        
        if str(original_value) != str(processed_value):
            print(f"  âš ï¸  æ•°æ®ä¸ä¸€è‡´!")
    
    # 6. æ£€æŸ¥è§†é¢‘å’Œå°é¢URL
    print(f"\nåª’ä½“URLåˆ†æ:")
    video_url_original = writer._extract_video_url(video_data)
    cover_url_original = writer._extract_cover_url(video_data)
    
    print(f"è§†é¢‘URL: {video_url_original}")
    print(f"å°é¢URL: {cover_url_original}")
    
    # 7. æ£€æŸ¥æ—¶é—´æ ¼å¼
    if 'create_time' in video_data:
        create_time = video_data['create_time']
        print(f"\næ—¶é—´æ ¼å¼åˆ†æ:")
        print(f"åŸå§‹æ—¶é—´: {create_time} ({type(create_time).__name__})")
        
        converted_time = DouyinDataTypeMapper.convert_value('create_time', create_time)
        print(f"è½¬æ¢æ—¶é—´: {converted_time} ({type(converted_time).__name__})")
    
    return video_data, processed_fields

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python debug_data.py <æŠ–éŸ³ç”¨æˆ·URL>")
        print("ç¤ºä¾‹: python debug_data.py 'https://www.douyin.com/user/MS4wLjABAAAAZOOYD9flTg8JWjfjM5EmEgRgte_SJQ9Kp3YrtasgHJgEHK6wI0YKhSwQBDZQFDW6'")
        return
    
    url = sys.argv[1]
    analyze_single_video(url, max_videos=1)

if __name__ == "__main__":
    main()